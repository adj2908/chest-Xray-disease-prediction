{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning project \n",
    "\n",
    "## Predicting the disease type using X ray images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built of Cnn model after all preprocessing has been done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('train.csv')\n",
    "test_data=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_norm=np.load('normalized_image_array.npy') #loading the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18577\n",
      "(18577, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train_norm))\n",
    "print(x_train_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final training data is an 18577x128x128x3 array. This mean that it is an array of 18577 images of size 128x128 with 3 as the RGB spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adityajainkld/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "# Split the 'features' and 'income' data into training and testing sets\n",
    "target=train_data['detected']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train_norm, target, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross validation** Splitting our data into training and testing part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adityajainkld/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label encoding is a process by which categorical variables are converted into a form that could be provided to trainning algorithms to do a better job in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_y_train = encoder.transform(y_train)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y_train = np_utils.to_categorical(encoded_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_test)\n",
    "encoded_y_test = encoder.transform(y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y_test = np_utils.to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes=y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model and training it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use keras module for this problem. Keras is a high-level API written in Python. It runs on top of Tensorflow, CNTK or Theano. It is relatively easy to use and is very fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple CNN model\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten,Convolution2D, MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model flattened out to:  (None, 128)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 127, 127, 32)      416       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 126, 126, 32)      4128      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 125, 125, 32)      4128      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 125, 125, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 59, 59, 64)        32832     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 59, 59, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 56, 56, 64)        65600     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 21, 21, 128)       524416    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 128)       1048704   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              528384    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 14)                57358     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 19,047,278\n",
      "Trainable params: 19,047,278\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "'''\n",
    "First set of three layers\n",
    "Image Size: 128 x 128\n",
    "nb_filters = 64\n",
    "kernel_size = 4,4\n",
    "'''\n",
    "\n",
    "nb_filters = 32\n",
    "kernel_size = (2,2)\n",
    "model.add(Convolution2D(nb_filters, (kernel_size[0], kernel_size[1]),\n",
    "                 padding='valid',\n",
    "                 strides=1,\n",
    "                 input_shape = (128,128,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(nb_filters, (kernel_size[0], kernel_size[1])))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(nb_filters, (kernel_size[0], kernel_size[1])))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "'''\n",
    "Second set of three layers\n",
    "Image Size: 128 x 128\n",
    "nb_filters = 62\n",
    "kernel_size = 4,4\n",
    "'''\n",
    "\n",
    "nb_filters = 64\n",
    "kernel_size = (4, 4)\n",
    "\n",
    "model.add(Convolution2D(nb_filters, (kernel_size[0], kernel_size[1])))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(nb_filters, (kernel_size[0], kernel_size[1])))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1])))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "'''\n",
    "Third set of three layers\n",
    "Image Size: 64 x 64\n",
    "nb_filters = 128\n",
    "kernel_size = 8,8\n",
    "'''\n",
    "\n",
    "nb_filters = 128\n",
    "kernel_size = (8, 8)\n",
    "\n",
    "model.add(Convolution2D(nb_filters, (kernel_size[0], kernel_size[1])))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(nb_filters, (kernel_size[0], kernel_size[1])))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1])))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(12, 12)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "print(\"Model flattened out to: \", model.output_shape)\n",
    "\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(y_train.shape[1]))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"ml_project_cnn_wts.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "early_stops = EarlyStopping(patience=7, monitor='acc')\n",
    "callbacks_list = [checkpoint,early_stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "13003/13003 [==============================] - 1316s 101ms/step - loss: 2.1912 - acc: 0.3122\n",
      "\n",
      "Epoch 00001: acc did not improve\n",
      "Epoch 2/7\n",
      "13003/13003 [==============================] - 1324s 102ms/step - loss: 2.1902 - acc: 0.3122\n",
      "\n",
      "Epoch 00002: acc did not improve\n",
      "Epoch 3/7\n",
      "13003/13003 [==============================] - 1312s 101ms/step - loss: 2.1891 - acc: 0.3122\n",
      "\n",
      "Epoch 00003: acc did not improve\n",
      "Epoch 4/7\n",
      "13003/13003 [==============================] - 1318s 101ms/step - loss: 2.1892 - acc: 0.3122\n",
      "\n",
      "Epoch 00004: acc did not improve\n",
      "Epoch 5/7\n",
      " 7424/13003 [================>.............] - ETA: 9:22 - loss: 2.1830 - acc: 0.3168"
     ]
    }
   ],
   "source": [
    "hist_model=model.fit(X_train,y_train,epochs=7,batch_size=128,callbacks=callbacks_list,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('ml_project_cnn_wts.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "acc: 29.92%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "json_file = open('model1.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"ml_project_cnn_wts.best.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## MODEL #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 30, 30, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 14)                3598      \n",
      "=================================================================\n",
      "Total params: 3,535,022\n",
      "Trainable params: 3,535,022\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3,3), activation='relu', padding='same',input_shape = (128,128,3)))\n",
    "model.add(Convolution2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(64, (3,3), activation='relu', padding='same'))\n",
    "model.add(Convolution2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(128, (3,3), activation='relu', padding='same'))\n",
    "model.add(Convolution2D(128, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stops = EarlyStopping(patience=7, monitor='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"ml_project_cnn_wts_2.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "early_stops = EarlyStopping(patience=7, monitor='acc')\n",
    "callbacks_list = [checkpoint,early_stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "13003/13003 [==============================] - 891s 69ms/step - loss: 2.2068 - acc: 0.3053\n",
      "Epoch 2/25\n",
      "13003/13003 [==============================] - 882s 68ms/step - loss: 2.1311 - acc: 0.3139\n",
      "Epoch 3/25\n",
      "13003/13003 [==============================] - 886s 68ms/step - loss: 2.1016 - acc: 0.3198\n",
      "Epoch 4/25\n",
      "13003/13003 [==============================] - 888s 68ms/step - loss: 2.0788 - acc: 0.3278\n",
      "Epoch 5/25\n",
      "13003/13003 [==============================] - 888s 68ms/step - loss: 2.0536 - acc: 0.3335\n",
      "Epoch 6/25\n",
      "13003/13003 [==============================] - 889s 68ms/step - loss: 2.0329 - acc: 0.3426\n",
      "Epoch 7/25\n",
      "13003/13003 [==============================] - 884s 68ms/step - loss: 2.0041 - acc: 0.3492\n",
      "Epoch 8/25\n",
      "13003/13003 [==============================] - 883s 68ms/step - loss: 1.9748 - acc: 0.3560\n",
      "Epoch 9/25\n",
      "13003/13003 [==============================] - 890s 68ms/step - loss: 1.9474 - acc: 0.3619\n",
      "Epoch 10/25\n",
      "13003/13003 [==============================] - 888s 68ms/step - loss: 1.9166 - acc: 0.3717\n",
      "Epoch 11/25\n",
      "13003/13003 [==============================] - 894s 69ms/step - loss: 1.8667 - acc: 0.3855\n",
      "Epoch 12/25\n",
      "13003/13003 [==============================] - 889s 68ms/step - loss: 1.8479 - acc: 0.3940\n",
      "Epoch 13/25\n",
      "13003/13003 [==============================] - 883s 68ms/step - loss: 1.7937 - acc: 0.4068\n",
      "Epoch 14/25\n",
      "13003/13003 [==============================] - 887s 68ms/step - loss: 1.7462 - acc: 0.4217\n",
      "Epoch 15/25\n",
      "13003/13003 [==============================] - 890s 68ms/step - loss: 1.7067 - acc: 0.4277\n",
      "Epoch 16/25\n",
      "13003/13003 [==============================] - 889s 68ms/step - loss: 1.6342 - acc: 0.4533\n",
      "Epoch 17/25\n",
      "13003/13003 [==============================] - 899s 69ms/step - loss: 1.5932 - acc: 0.4642\n",
      "Epoch 18/25\n",
      "13003/13003 [==============================] - 892s 69ms/step - loss: 1.5385 - acc: 0.4895\n",
      "Epoch 19/25\n",
      "13003/13003 [==============================] - 897s 69ms/step - loss: 1.4789 - acc: 0.5010\n",
      "Epoch 20/25\n",
      "13003/13003 [==============================] - 889s 68ms/step - loss: 1.4130 - acc: 0.5214\n",
      "Epoch 21/25\n",
      "13003/13003 [==============================] - 891s 69ms/step - loss: 1.3704 - acc: 0.5357\n",
      "Epoch 22/25\n",
      "13003/13003 [==============================] - 889s 68ms/step - loss: 1.3115 - acc: 0.5554\n",
      "Epoch 23/25\n",
      "13003/13003 [==============================] - 884s 68ms/step - loss: 1.2591 - acc: 0.5772\n",
      "Epoch 24/25\n",
      "13003/13003 [==============================] - 891s 69ms/step - loss: 1.2072 - acc: 0.5931\n",
      "Epoch 25/25\n",
      "13003/13003 [==============================] - 884s 68ms/step - loss: 1.1678 - acc: 0.6099\n"
     ]
    }
   ],
   "source": [
    "#model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=64,verbose=3)\n",
    "model1_adam=model.fit(X_train, y_train, batch_size=128, epochs=25,verbose=1)\n",
    "\n",
    "# Final evaluation of the model\n",
    "#scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "#print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 30.27%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep networks need large amount of training data to achieve good performance. To build a powerful image classifier using very little training data, **image augmentation** is usually required to boost the performance of deep networks. Image augmentation artificially creates training images through different ways of processing or combination of multiple processing, such as **random rotation, shifts, shear and flips, etc.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
